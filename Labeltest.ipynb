{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec56dba-0f52-42d6-950c-1dad1212e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.10.0\n",
      "NumPy     : 1.23.5\n",
      "Gefundene GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1) Imports, GPU-Check & Reproducibility\n",
    "\n",
    "import os, sys, glob, re, json, random, datetime, warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"NumPy     :\", np.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"Gefundene GPUs:\", gpus)\n",
    "else:\n",
    "    print(\"WARNUNG: Keine GPU erkannt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4ab83a-8d90-4b2f-9a29-cb596309e5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording-Ordner:\n",
      "  • E:\\dmsv_labeltest\\datasets\\msiv6_recordings\\25_07_08\n",
      "  • E:\\dmsv_labeltest\\datasets\\msiv6_recordings\\25_07_16\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 2) Konfiguration & Pfade\n",
    "\n",
    "BASE_DIR = r\"E:\\dmsv_labeltest\"\n",
    "\n",
    "MSI_BASE_DIR = os.path.join(BASE_DIR, \"datasets\", \"msiv6_recordings\")\n",
    "ANN_ROOT     = os.path.join(BASE_DIR, \"Datasets\", \"annotations\")  # ggf. 'datasets' statt 'Datasets'!\n",
    "\n",
    "OUTPUTS_DIR  = os.path.join(BASE_DIR, \"outputs\")\n",
    "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
    "\n",
    "# Nur bestimmte Ordner? [] = alle\n",
    "INCLUDE_RECORDING_DIRS = [\"25_07_08\", \"25_07_16\"]  \n",
    "\n",
    "def list_recording_dirs(base_dir, include=None):\n",
    "    subs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    subs_sorted = sorted(subs)\n",
    "    if include and len(include) > 0:\n",
    "        subs_sorted = [d for d in subs_sorted if d in include]\n",
    "    return [os.path.join(base_dir, d) for d in subs_sorted]\n",
    "\n",
    "RECORDING_DIRS = list_recording_dirs(MSI_BASE_DIR, INCLUDE_RECORDING_DIRS)\n",
    "\n",
    "print(\"Recording-Ordner:\")\n",
    "for p in RECORDING_DIRS: print(\"  •\", p)\n",
    "\n",
    "# Training-Parameter\n",
    "NUM_CHANNELS   = 13\n",
    "NUM_CLASSES    = None  # wird aus COCO gesetzt\n",
    "PATCH_SIZE     = 80\n",
    "BATCH_SIZE     = 32\n",
    "EPOCHS         = 80\n",
    "CACHE_DATASET  = False\n",
    "SHUFFLE_BUFFER = 2048\n",
    "\n",
    "RUN_NAME = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "LOG_DIR  = os.path.join(OUTPUTS_DIR, \"logs\", RUN_NAME)\n",
    "CKPT_DIR = os.path.join(OUTPUTS_DIR, \"checkpoints\", RUN_NAME)\n",
    "os.makedirs(LOG_DIR, exist_ok=True); os.makedirs(CKPT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa28a3a-c30c-4218-965d-18ccc4cd83d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Local\\Temp\\ipykernel_18440\\2163021651.py:16: UserWarning: pycocotools nicht verfügbar.\n",
      "  except: maskUtils=None; warnings.warn(\"pycocotools nicht verfügbar.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_CLASSES = 7\n",
      "Szenen: 42\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 3) COCO → Masken (.npy), 255 = unlabeled\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "ANNOTATION_FILE = os.path.join(ANN_ROOT, \"metall_annotations.json\")\n",
    "GEN_MASK_DIR = os.path.join(ANN_ROOT, \"generated_masks\")\n",
    "os.makedirs(GEN_MASK_DIR, exist_ok=True)\n",
    "\n",
    "CUT_BORDERS = True\n",
    "ERODE_KERNEL = (3, 3)\n",
    "\n",
    "try: import cv2\n",
    "except: cv2=None\n",
    "try: from pycocotools import mask as maskUtils\n",
    "except: maskUtils=None; warnings.warn(\"pycocotools nicht verfügbar.\")\n",
    "\n",
    "def decode_poly(polys, hw):\n",
    "    H,W = hw; m=Image.new(\"L\",(W,H),0); d=ImageDraw.Draw(m)\n",
    "    for poly in polys:\n",
    "        if len(poly)>=6:\n",
    "            pts=[(poly[i],poly[i+1]) for i in range(0,len(poly),2)]\n",
    "            d.polygon(pts,outline=1,fill=1)\n",
    "    return np.array(m,dtype=np.uint8)\n",
    "\n",
    "def decode_rle_uncompressed(counts,size):\n",
    "    H,W=size; arr=np.zeros(H*W,dtype=np.uint8); idx=0; val=0\n",
    "    for run in counts:\n",
    "        if val==1: arr[idx:idx+run]=1\n",
    "        idx+=run; val^=1\n",
    "    return arr.reshape((H,W),order=\"F\")\n",
    "\n",
    "def decode_seg(seg, hw):\n",
    "    H,W=hw\n",
    "    if maskUtils and isinstance(seg,dict) and \"counts\" in seg:\n",
    "        rle=seg\n",
    "        if isinstance(rle[\"counts\"],list):\n",
    "            rle=maskUtils.frPyObjects(rle,H,W)\n",
    "        m=maskUtils.decode(rle); \n",
    "        if m.ndim==3: m=np.any(m,2).astype(np.uint8)\n",
    "        return m\n",
    "    if isinstance(seg,dict) and isinstance(seg.get(\"counts\"),list):\n",
    "        return decode_rle_uncompressed(seg[\"counts\"], seg[\"size\"])\n",
    "    if isinstance(seg,list) and seg: return decode_poly(seg,hw)\n",
    "    return None\n",
    "\n",
    "def ts_from_rgb(name):\n",
    "    m=re.search(r\"(\\d{2}_\\d{2}_\\d{2}(?:_\\d{2}){3})\",name)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "with open(ANNOTATION_FILE,\"r\",encoding=\"utf-8\") as f: coco=json.load(f)\n",
    "images={im[\"id\"]:im for im in coco[\"images\"]}\n",
    "img_hw={i:(int(im[\"height\"]),int(im[\"width\"])) for i,im in images.items()}\n",
    "img_ts={ts_from_rgb(im[\"file_name\"]):i for i,im in images.items() if ts_from_rgb(im[\"file_name\"])}\n",
    "\n",
    "cats={c[\"id\"]:c[\"name\"] for c in coco[\"categories\"]}\n",
    "fg_ids=[cid for cid,nm in cats.items() if nm.lower().replace(\"-\",\"_\")!=\"kein_metall\"]\n",
    "fg_ids=sorted(fg_ids)\n",
    "cid2cls={cid:i for i,cid in enumerate(fg_ids)}\n",
    "NUM_CLASSES=len(fg_ids)\n",
    "print(\"NUM_CLASSES =\",NUM_CLASSES)\n",
    "\n",
    "anns_by_img={}\n",
    "for ann in coco[\"annotations\"]: anns_by_img.setdefault(ann[\"image_id\"],[]).append(ann)\n",
    "\n",
    "def iter_all_msi(dirs):\n",
    "    for rec in dirs:\n",
    "        for p in glob.glob(os.path.join(rec,\"**\",\"registered_scene\",\"registered_scene_*.npy\"),recursive=True):\n",
    "            yield p\n",
    "\n",
    "msi_files=sorted(iter_all_msi(RECORDING_DIRS))\n",
    "scenes=[]\n",
    "\n",
    "for msi in msi_files:\n",
    "    ts=re.search(r\"registered_scene_(.+?)\\.npy$\",os.path.basename(msi))\n",
    "    ts=ts.group(1) if ts else None\n",
    "    if not ts or ts not in img_ts: continue\n",
    "    img_id=img_ts[ts]; H,W=img_hw[img_id]; anns=anns_by_img.get(img_id,[])\n",
    "    mask=np.full((H,W),255,dtype=np.uint8)\n",
    "    for a in anns:\n",
    "        cls=cid2cls.get(a[\"category_id\"],None)\n",
    "        if cls is None: continue\n",
    "        m=decode_seg(a[\"segmentation\"],(H,W))\n",
    "        if m is None: continue\n",
    "        if CUT_BORDERS and cv2 is not None:\n",
    "            k=cv2.getStructuringElement(cv2.MORPH_RECT,ERODE_KERNEL)\n",
    "            m=cv2.erode(m,k,1)\n",
    "        mask[m>0]=cls\n",
    "    msi_mm=np.load(msi,mmap_mode=\"r\")\n",
    "    if (msi_mm.shape[0],msi_mm.shape[1])!=(H,W):\n",
    "        mask=np.array(Image.fromarray(mask).resize((msi_mm.shape[1],msi_mm.shape[0]),Image.NEAREST))\n",
    "    out=os.path.join(GEN_MASK_DIR,f\"mask_{ts}.npy\"); np.save(out,mask)\n",
    "    scenes.append({\"msi\":msi,\"mask\":out})\n",
    "\n",
    "print(\"Szenen:\",len(scenes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b49711-3c70-4209-8c5e-70390d0eb9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 4) Patches & Dataset (VALID, remove_unlabeled)\n",
    "\n",
    "def standardize(msi,eps=1e-6):\n",
    "    m=msi.reshape(-1,msi.shape[-1]).mean(0); s=msi.reshape(-1,msi.shape[-1]).std(0); s=np.where(s<eps,1,s)\n",
    "    return (msi-m)/s\n",
    "\n",
    "def extract_patches(arr,ks):\n",
    "    x4=tf.expand_dims(arr,0)\n",
    "    patches=tf.image.extract_patches(x4,[1,ks,ks,1],[1,ks,ks,1],[1,1,1,1],\"VALID\")\n",
    "    flat=tf.reshape(patches,(-1,ks,ks,arr.shape[-1]))\n",
    "    return flat.numpy()\n",
    "\n",
    "REMOVE_UNLABELED=True\n",
    "\n",
    "def build_patches(scenes):\n",
    "    Xs,Ys=[],[]\n",
    "    for it in scenes:\n",
    "        msi=np.load(it[\"msi\"]).astype(np.float32); msi=standardize(msi)\n",
    "        y=np.load(it[\"mask\"]).astype(np.int32)\n",
    "        xp=extract_patches(msi,PATCH_SIZE)\n",
    "        yp=extract_patches(y[...,None],PATCH_SIZE)[...,0]\n",
    "        if REMOVE_UNLABELED:\n",
    "            keep=(yp!=255).any((1,2))\n",
    "            xp,yp=xp[keep],yp[keep]\n",
    "        Xs.append(xp); Ys.append(yp)\n",
    "    return np.concatenate(Xs),np.concatenate(Ys)\n",
    "\n",
    "X,Y=build_patches(scenes)\n",
    "print(\"Patches:\",X.shape,Y.shape)\n",
    "\n",
    "def make_ds(X,Y,batch,train=True):\n",
    "    ds=tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "    if train: ds=ds.shuffle(min(len(X),SHUFFLE_BUFFER),seed=SEED)\n",
    "    def _map(x,y):\n",
    "        sw=tf.cast(tf.not_equal(y,255),tf.float32)\n",
    "        return x,y,sw\n",
    "    ds=ds.map(_map,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if CACHE_DATASET: ds=ds.cache()\n",
    "    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "split=int(0.8*len(X))\n",
    "train_ds=make_ds(X[:split],Y[:split],BATCH_SIZE,True)\n",
    "val_ds  =make_ds(X[split:],Y[split:],BATCH_SIZE,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ea004-4240-4697-8852-d64b6899c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 5) Modell, Loss & Metriken (255 ignorieren)\n",
    "\n",
    "from tensorflow.keras import layers,models,losses,optimizers\n",
    "\n",
    "def build_unet(c_in=NUM_CHANNELS,c_out=NUM_CLASSES,base=8):\n",
    "    inp=layers.Input((PATCH_SIZE,PATCH_SIZE,c_in))\n",
    "    def conv(x,f):\n",
    "        for _ in range(2):\n",
    "            x=layers.Conv2D(f,3,padding=\"same\",use_bias=False)(x)\n",
    "            x=layers.BatchNormalization()(x); x=layers.Activation(\"relu\")(x)\n",
    "        return x\n",
    "    def enc(x,f): c=conv(x,f); p=layers.MaxPooling2D()(c); return c,p\n",
    "    def dec(x,s,f): x=layers.Conv2DTranspose(f,2,2,padding=\"same\")(x); x=layers.Concatenate()([x,s]); return conv(x,f)\n",
    "    c1,p1=enc(inp,base); c2,p2=enc(p1,base*2); c3,p3=enc(p2,base*4); c4,p4=enc(p3,base*8)\n",
    "    bn=conv(p4,base*16)\n",
    "    d1=dec(bn,c4,base*8); d2=dec(d1,c3,base*4); d3=dec(d2,c2,base*2); d4=dec(d3,c1,base)\n",
    "    out=layers.Conv2D(c_out,1,activation=\"softmax\")(d4)\n",
    "    return models.Model(inp,out)\n",
    "\n",
    "_scc=losses.SparseCategoricalCrossentropy(reduction=losses.Reduction.NONE)\n",
    "def loss(y,yhat): return _scc(y,yhat)\n",
    "\n",
    "class AccIgnore255(tf.keras.metrics.Metric):\n",
    "    def __init__(self): super().__init__(\"accuracy\"); self.m=tf.keras.metrics.Mean()\n",
    "    def update_state(self,y,yp,**k):\n",
    "        pr=tf.argmax(yp,-1,tf.int32); y=tf.reshape(y,[-1]); pr=tf.reshape(pr,[-1])\n",
    "        m=tf.not_equal(y,255); self.m.update_state(tf.reduce_mean(tf.cast(tf.equal(tf.boolean_mask(y,m),tf.boolean_mask(pr,m)),tf.float32)))\n",
    "    def result(self): return self.m.result()\n",
    "    def reset_states(self): self.m.reset_states()\n",
    "\n",
    "model=build_unet()\n",
    "model.compile(optimizers.Adam(1e-3),loss=loss,metrics=[AccIgnore255()])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9d374-f1d5-49f2-92d1-a1f4958c4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 6) Training\n",
    "\n",
    "cb=[\n",
    " tf.keras.callbacks.ModelCheckpoint(os.path.join(CKPT_DIR,\"best.h5\"),save_best_only=True,save_weights_only=True,monitor=\"val_accuracy\",mode=\"max\"),\n",
    " tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",mode=\"max\",patience=10,restore_best_weights=True),\n",
    " tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR)\n",
    "]\n",
    "history=model.fit(train_ds,validation_data=val_ds,epochs=EPOCHS,callbacks=cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd96d7b-ec94-4e70-be64-f1f5e17c46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 7) Beispiel-Visualisierung\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PALETTE=np.array([[0,0,0],[255,0,0],[0,255,0],[0,0,255],[255,255,0],[255,0,255],[0,255,255],[128,128,0],[128,0,128]])\n",
    "\n",
    "x_s,y_s,_=next(iter(val_ds))\n",
    "pred=model.predict(x_s)\n",
    "y_hat=np.argmax(pred,-1)\n",
    "\n",
    "n=min(3,len(x_s))\n",
    "plt.figure(figsize=(9,3*n))\n",
    "for i in range(n):\n",
    "    rgb=(x_s[i][..., :3]-x_s[i][..., :3].min())/(x_s[i][..., :3].ptp()+1e-6)\n",
    "    plt.subplot(n,3,i*3+1); plt.imshow(rgb); plt.axis(\"off\"); plt.title(\"MSI\")\n",
    "    plt.subplot(n,3,i*3+2); plt.imshow(PALETTE[y_s[i]]); plt.axis(\"off\"); plt.title(\"GT\")\n",
    "    plt.subplot(n,3,i*3+3); plt.imshow(PALETTE[y_hat[i]]); plt.axis(\"off\"); plt.title(\"Pred\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617532e-eb4b-4ea8-8dca-c3313a9ce94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 8) Export\n",
    "\n",
    "cfg={\"NUM_CLASSES\":NUM_CLASSES,\"PATCH_SIZE\":PATCH_SIZE,\"BATCH_SIZE\":BATCH_SIZE,\"EPOCHS\":EPOCHS,\"CHANNELS\":NUM_CHANNELS}\n",
    "with open(os.path.join(OUTPUTS_DIR,f\"config_{RUN_NAME}.json\"),\"w\") as f: json.dump(cfg,f,indent=2)\n",
    "\n",
    "model.save(os.path.join(OUTPUTS_DIR,f\"savedmodel_{RUN_NAME}\"))\n",
    "print(\"Gespeichert unter\",os.path.join(OUTPUTS_DIR,f\"savedmodel_{RUN_NAME}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecbb7b-3206-4442-b57a-c902e19c1d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmsv_labeltest (TF2.10)",
   "language": "python",
   "name": "dmsv_labeltest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
